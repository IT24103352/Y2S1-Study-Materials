# LECTURE 7 - Neural Networks and Deep Learning

**Module:** IT2011 - Artificial Intelligence and Machine Learning  
**Lecturer:** Dr. Lakmini Abeywardhana  
**Academic Year:** Year 02, Semester 01  
**Institution:** Sri Lanka Institute of Information Technology (SLIIT)  
**Faculty:** Faculty of Computing  
**Student:** IT24103352  
**Date:** 2025-01-23  
**Current Time (UTC):** 2025-01-23 10:01:40

---

## Table of Contents

- [What is Deep Learning?](#what-is-deep-learning)
- [Introduction to Neural Networks](#introduction-to-neural-networks)
- [The Perceptron](#the-perceptron)
- [Activation Functions](#activation-functions)
- [Multi-Layer Neural Networks](#multi-layer-neural-networks)
- [How Neural Networks Learn](#how-neural-networks-learn)
- [Forward Propagation](#forward-propagation)
- [Backpropagation](#backpropagation)
- [Types of Neural Networks](#types-of-neural-networks)

---

## What is Deep Learning?

### Definition

**Deep Learning** is a way for computers to learn patterns and make decisions, inspired by how the human brain works.

---

### Part of Machine Learning (ML)

#### Traditional ML:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Algorithms need MANUAL feature        â”‚
â”‚  selection                             â”‚
â”‚                                        â”‚
â”‚  Example:                              â”‚
â”‚  Detecting edges in an image requires  â”‚
â”‚  explicit programming                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Deep Learning:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Learns features AUTOMATICALLY         â”‚
â”‚                                        â”‚
â”‚  Example:                              â”‚
â”‚  Finds eyes, nose, face without        â”‚
â”‚  explicit coding                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Analogy

```
TRADITIONAL ML:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Cooking with a recipe  â”‚
    â”‚  Steps are predefined   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEEP LEARNING:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Chef who experiments   â”‚
    â”‚  Learns by tasting      â”‚
    â”‚  Improves over time     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Biological Inspiration

### Biological Neuron Structure

```
     Dendrites
        â•±â”‚â•²
       â•± â”‚ â•²
      â—â”€â”€â—â”€â”€â—  â† Receives signals
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Cell Bodyâ”‚  â† Processes information
    â”‚(Nucleus)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
      Axonâ”‚  â† Transmits signals
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Synapse â”‚  â† Connection to next neuron
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components:**
- **Dendrites:** Receive incoming signals
- **Cell Body:** Processes information
- **Axon:** Transmits output signals
- **Synapse:** Connection point to other neurons

---

### Artificial Neuron Model

```
Input Signals â†’ Weights â†’ Weighted Sum â†’ Activation â†’ Output

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  xâ‚     â”‚â”€â”€â”€â”€â”€wâ‚â”€â”€â”€â”€â”
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  xâ‚‚     â”‚â”€â”€â”€â”€â”€wâ‚‚â”€â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”œâ”€â”€â†’ Î£ wâ‚xâ‚ â†’ Ï†(Â·) â†’ Output
â”‚  xâ‚ƒ     â”‚â”€â”€â”€â”€â”€wâ‚ƒâ”€â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚  xâ‚„     â”‚â”€â”€â”€â”€â”€wâ‚„â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Steps:
1. Input signals (xâ‚, xâ‚‚, xâ‚ƒ, xâ‚„)
2. Multiply by weights (wâ‚, wâ‚‚, wâ‚ƒ, wâ‚„)
3. Weighted sum: Î£(wáµ¢xáµ¢)
4. Nonlinear activation: Ï†(sum)
5. Output
```

---

## Introduction to Neural Networks

### What is a Neural Network?

**Definition:**  
A neural network is a computational model inspired by the way biological neural networks in the human brain process information.

**Structure:**  
Made up of **layers** of interconnected **nodes** or "neurons."

---

## Structure of a Neuron

### Mathematical Model

```
Inputs â†’ Weights â†’ Summation â†’ Bias â†’ Activation â†’ Output

xâ‚ â”€â”€â”€â”€â”€w_{k1}â”€â”€â”€â”€â”
xâ‚‚ â”€â”€â”€â”€â”€w_{k2}â”€â”€â”€â”€â”¤
   â‹®        â‹®      â”œâ”€â”€â†’ Î£ â”€â”€â†’ + b_k â”€â”€â†’ Ï†(Â·) â”€â”€â†’ y_k
x_m â”€â”€â”€â”€â”€w_{km}â”€â”€â”€â”˜

Where:
  xáµ¢      = Input signals
  w_{ki}  = Synaptic weights
  Î£       = Summation (u_k = Î£ w_{ki}x_i)
  b_k     = Bias
  Ï†(Â·)    = Activation function
  y_k     = Output
```

---

### Complete Mathematical Representation

**Step 1: Weighted Sum**
```
u_k = Î£(i=1 to m) w_{ki} Ã— x_i
```

**Step 2: Add Bias**
```
v_k = u_k + b_k
```

**Step 3: Apply Activation**
```
y_k = Ï†(v_k) = Ï†(u_k + b_k)
```

---

## Basic Terminology

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NEURON (NODE)                         â”‚
â”‚  Smallest processing unit              â”‚
â”‚  Performs: Î£(wáµ¢xáµ¢) + b â†’ Ï†(Â·)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYERS                                â”‚
â”‚                                        â”‚
â”‚  1. INPUT LAYER                        â”‚
â”‚     Raw data enters                    â”‚
â”‚                                        â”‚
â”‚  2. HIDDEN LAYER(S)                    â”‚
â”‚     Where learning happens             â”‚
â”‚     Can have multiple layers           â”‚
â”‚                                        â”‚
â”‚  3. OUTPUT LAYER                       â”‚
â”‚     Final prediction                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WEIGHTS                               â”‚
â”‚  Strength of connection between neuronsâ”‚
â”‚  Learned during training               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BIAS                                  â”‚
â”‚  Adjustment term                       â”‚
â”‚  Shifts activation function            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ACTIVATION FUNCTION                   â”‚
â”‚  Adds non-linearity                    â”‚
â”‚  Enables solving complex problems      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Classification Problems

### Definition

**Classification:**  
Identifying which category a given example belongs to.

---

### Types of Classification

#### 1. Binary Classification (Two Classes)

```
Examples:
â”œâ”€â”€ Disease / No Disease
â”œâ”€â”€ Spam / Not Spam
â”œâ”€â”€ Buy / Do Not Buy
â”œâ”€â”€ Pass / Fail
â””â”€â”€ Yes / No
```

---

#### 2. Multi-Class Classification (More Than Two Classes)

```
Examples:
â”œâ”€â”€ Hand-written character recognition (0-9, A-Z)
â”œâ”€â”€ Face recognition (Person 1, 2, 3, ...)
â”œâ”€â”€ Animal classification (Cat, Dog, Bird, ...)
â””â”€â”€ Product categories (Electronics, Clothing, Food, ...)
```

---

## The Perceptron

### History

**Introduced:** 1958  
**Inventor:** Frank Rosenblatt  
**Type:** Binary classifier  

**Purpose:**  
Determines whether an input belongs to one of two classes.

---

### How Perceptron Works

**Process:**
1. Takes several **binary** or **real-valued** inputs
2. Applies **weights** to them
3. **Sums** the weighted results
4. Adds a **bias**
5. Passes through **activation function** (step function)

---

### Mathematical Representation

```
y = {
  1  if (w Â· x + b) â‰¥ 0
  0  otherwise
}

Where:
  y = output (prediction)
  w = weight vector
  x = input vector
  b = bias
  Â· = dot product
```

---

### Perceptron Diagram

```
Inputs:          Weights:         
xâ‚€ = 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ wâ‚€ (bias) â”€â”€â”
xâ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ wâ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
xâ‚‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ wâ‚‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”œâ”€â”€â†’ Î£ z = Î£wáµ¢xáµ¢
   â‹®                  â‹®         â”‚
x_m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ w_m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Activation    â”‚
                         â”‚ Output = 1    â”‚
                         â”‚   if z â‰¥ 0    â”‚
                         â”‚ Output = 0    â”‚
                         â”‚   otherwise   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Question:**  
Why do we need bias (wâ‚€, xâ‚€=1)?

**Answer:**  
Bias allows the decision boundary to shift, not just pass through origin.

---

### What is a Perceptron? (Simple Terms)

**Simplest form of neural network**

**Components:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUTS                                â”‚
â”‚  Example: Exam marks, height, etc.     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WEIGHTS                               â”‚
â”‚  Importance of each input              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BIAS                                  â”‚
â”‚  Adjusts output up/down                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ACTIVATION FUNCTION                   â”‚
â”‚  Decides output: YES / NO              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Linear Separability

### Linearly Separable Classes

```
      Class Câ‚
    â—  â—  â—  â—
    
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† Decision Boundary
                     (Hyperplane/Line)
    
    â—‹  â—‹  â—‹  â—‹
      Class Câ‚‚

âœ… Can be separated by a straight line
âœ… Perceptron can solve this
```

---

### Non-Linearly Separable Classes

```
    â—  â—
  â—  â—‹  â—‹  â—
    â—‹  â—
  â—  â—‹  â—‹  â—
    â—  â—

âŒ Cannot be separated by a straight line
âŒ Perceptron CANNOT solve this
```

**Mathematical Representation:**
```
y = 1  if (wÂ·x + b) â‰¥ 0
y = 0  otherwise

Works only when classes can be separated 
by a hyperplane (straight line in 2D)
```

---

### Perceptron Limitation

**Problem:**  
When classes Câ‚ and Câ‚‚ are too close or intermingled, they become **nonlinearly separable**.

**Consequence:**  
Beyond the computing capability of a single perceptron.

**Solution:**  
Multi-layer perceptrons (neural networks with hidden layers).

---

## Perceptron Learning

### Perceptron Convergence Theorem

**Proven by Rosenblatt (1958, 1962):**

**Statement:**  
If training patterns are drawn from **two linearly separable classes**, then the perceptron algorithm:
- âœ… **Converges** (reaches a solution)
- âœ… **Positions** decision surface as hyperplane between classes

**Requirement:**  
Data must be linearly separable!

---

## Perceptron Convergence Algorithm

### Variables and Parameters

```
x(n) = (m+1)-by-1 input vector
     = [+1, xâ‚(n), xâ‚‚(n), ..., x_m(n)]áµ€

w(n) = (m+1)-by-1 weight vector
     = [b, wâ‚(n), wâ‚‚(n), ..., w_m(n)]áµ€
     where b = bias

y(n) = actual response (quantized output)
d(n) = desired response (true label)
Î·    = learning rate (0 < Î· < 1)
```

---

### Algorithm Steps

#### Step 1: Initialization
```
Set w(0) = 0 (all weights = 0)
Set n = 1 (time step)
```

---

#### Step 2: Activation
```
At time-step n:
- Apply input vector x(n)
- Apply desired response d(n)
```

---

#### Step 3: Compute Actual Response
```
y(n) = sgn[wáµ€(n)x(n)]

where sgn() is the signum function:
  sgn(z) = {
    +1  if z â‰¥ 0
    -1  if z < 0
  }
```

---

#### Step 4: Adapt Weight Vector
```
w(n+1) = w(n) + Î·[d(n) - y(n)]x(n)

where desired response:
  d(n) = {
    +1  if x(n) belongs to class Ï†â‚
    -1  if x(n) belongs to class Ï†â‚‚
  }
```

**Interpretation:**
```
If prediction correct: d(n) = y(n) â†’ no change
If prediction wrong:   d(n) â‰  y(n) â†’ update weights
```

---

#### Step 5: Continuation
```
n = n + 1 (increment time step)
Go back to Step 2
```

**Repeat until:**
- All samples correctly classified, OR
- Maximum iterations reached

---

### Update Rule Breakdown

**Weight Update:**
```
Î”w = Î· Ã— error Ã— input
   = Î· Ã— [d(n) - y(n)] Ã— x(n)

If correct:  error = 0 â†’ no change
If incorrect: error â‰  0 â†’ adjust weights
```

---

## Batch Perceptron Algorithm

### Motivation

**Previous algorithm:**
- âŒ No explicit cost function
- âŒ Single-sample correction only

**Batch approach:**
- âœ… Uses cost function
- âœ… Updates based on multiple samples
- âœ… More generalized

---

### Cost Function

**Definition:**
```
J(w) = Î£ (-wáµ€x(n)d(n))
       x(n)âˆˆğ•

where:
  ğ• = set of misclassified samples
```

**Interpretation:**
```
If all samples correctly classified:
  ğ• = empty set
  J(w) = 0 âœ…

If some samples misclassified:
  J(w) > 0 âŒ
```

---

### Gradient Vector

**Differentiate J(w) with respect to w:**
```
âˆ‡J(w) = Î£ (-x(n)d(n))
        x(n)âˆˆğ•

where âˆ‡ = gradient operator
```

---

### Method of Steepest Descent

**Concept:**  
Adjust weights in direction **opposite** to gradient.

**Why?**
- Gradient points toward **increasing** cost
- We want to **decrease** cost
- Therefore, move in **negative gradient** direction

```
       Cost
        â”‚     â•±â•²
        â”‚   â•±    â•²
        â”‚ â•±        â•²
        â”‚â•±          â•²
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Weights
         â†“
    Move down gradient
```

---

### Weight Update Rule

**Formula:**
```
w(n+1) = w(n) - Î·(n)âˆ‡J(w)

Substituting gradient:
w(n+1) = w(n) - Î·(n) Î£ (-x(n)d(n))
                    x(n)âˆˆğ•

Simplifying:
w(n+1) = w(n) + Î·(n) Î£ x(n)d(n)
                    x(n)âˆˆğ•
```

**Interpretation:**
```
- Start with current weights w(n)
- Calculate gradient from misclassified samples
- Move weights in direction that reduces error
- Step size controlled by learning rate Î·
```

---

## Activation Functions

### Why Activation Functions?

**Purpose:**
- âœ… Add **non-linearity** to the network
- âœ… Enable learning **complex patterns**
- âœ… Allow **multi-layer** networks to be powerful

**Without activation:**
```
Multiple layers of linear operations 
= Single linear operation
(No advantage to depth!)
```

**With activation:**
```
Non-linear transformations at each layer
â†’ Can approximate any function
```

---

### Common Activation Functions

#### 1. Sigmoid Function

**Formula:**
```
Ïƒ(x) = 1 / (1 + eâ»Ë£)
```

**Graph:**
```
Ïƒ(x)
1.0â”‚         â•­â”€â”€â”€â”€â”€â”€â”€â”€
   â”‚       â•±
0.5â”‚     â•±
   â”‚   â•±
0.0â”‚â•­â”€â”€
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
  -10    0    10
```

**Properties:**
- Range: (0, 1)
- S-shaped curve
- Smooth gradient
- Output interpretable as probability

**Use Cases:**
- Binary classification (output layer)
- Probability predictions

**Drawbacks:**
- Vanishing gradient problem
- Not zero-centered
- Computationally expensive

---

#### 2. Tanh (Hyperbolic Tangent)

**Formula:**
```
tanh(x) = (eË£ - eâ»Ë£) / (eË£ + eâ»Ë£)
```

**Graph:**
```
tanh(x)
 1.0â”‚         â•­â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚       â•±
 0.0â”‚     â•±
    â”‚   â•±
-1.0â”‚â•­â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
   -10    0    10
```

**Properties:**
- Range: (-1, 1)
- Zero-centered
- S-shaped curve
- Stronger gradients than sigmoid

**Use Cases:**
- Hidden layers
- When zero-centered output desired

**Drawbacks:**
- Still suffers from vanishing gradient
- Computationally expensive

---

#### 3. ReLU (Rectified Linear Unit)

**Formula:**
```
ReLU(x) = max(0, x) = {
  x  if x â‰¥ 0
  0  if x < 0
}
```

**Graph:**
```
ReLU(x)
10â”‚        â•±
  â”‚      â•±
 5â”‚    â•±
  â”‚  â•±
 0â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
 -10  0  10
```

**Properties:**
- Range: [0, âˆ)
- Computationally efficient
- Helps with vanishing gradient
- Sparse activation

**Use Cases:**
- **Most popular** for hidden layers
- Default choice in deep networks

**Advantages:**
- âœ… Fast to compute
- âœ… No vanishing gradient for positive values
- âœ… Sparse activation (some neurons output 0)

**Drawbacks:**
- âŒ "Dying ReLU" problem (neurons can become inactive)
- âŒ Not zero-centered

---

#### 4. Leaky ReLU

**Formula:**
```
Leaky ReLU(x) = {
  x      if x â‰¥ 0
  Î±x     if x < 0
}

where Î± = small constant (e.g., 0.01)
```

**Graph:**
```
Leaky ReLU(x)
10â”‚        â•±
  â”‚      â•±
 5â”‚    â•±
  â”‚  â•±
 0â”‚â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x
 -10  0  10
  (slight slope for x < 0)
```

**Properties:**
- Range: (-âˆ, âˆ)
- Small negative slope for x < 0
- Addresses "dying ReLU" problem

**Use Cases:**
- Alternative to ReLU
- When dying ReLU is a problem

**Advantages:**
- âœ… No dying neurons
- âœ… Still computationally efficient

---

### Activation Function Comparison

| Function | Range | Pros | Cons | Best For |
|----------|-------|------|------|----------|
| **Sigmoid** | (0, 1) | Smooth, probabilistic | Vanishing gradient | Output layer (binary) |
| **Tanh** | (-1, 1) | Zero-centered | Vanishing gradient | Hidden layers |
| **ReLU** | [0, âˆ) | Fast, no vanishing gradient | Dying ReLU | Hidden layers (default) |
| **Leaky ReLU** | (-âˆ, âˆ) | No dying neurons | Needs tuning Î± | Hidden layers |

---

## Limitations of Perceptron

### The XOR Problem

**XOR Truth Table:**
```
xâ‚  xâ‚‚  â”‚  XOR
â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€
0   0   â”‚   0
0   1   â”‚   1
1   0   â”‚   1
1   1   â”‚   0
```

**Visualization:**
```
xâ‚‚
 1â”‚  1    0
  â”‚
 0â”‚  0    1
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ xâ‚
   0    1

Cannot draw a single line to separate!
```

**Perceptron Limitation:**
```
âŒ Single perceptron CANNOT solve XOR
âŒ Problem is NOT linearly separable
```

---

### Solution: Multi-Layer Perceptrons (MLP)

**Add Hidden Layers:**
```
Input â†’ Hidden Layer(s) â†’ Output

With hidden layers:
âœ… Can solve XOR
âœ… Can learn non-linear patterns
âœ… Can approximate any function
```

---

## Types of Neural Networks

### 1. Shallow vs Deep Networks

#### Shallow Neural Networks
```
Input â†’ Hidden Layer â†’ Output
        (single layer)

Characteristics:
- Usually ONE hidden layer
- Fast training
- Less processing power
- Limited complexity
```

#### Deep Neural Networks
```
Input â†’ Hidden â†’ Hidden â†’ ... â†’ Hidden â†’ Output
        Layer 1   Layer 2       Layer N

Characteristics:
- MULTIPLE hidden layers
- Slower training
- More processing power
- Can learn complex patterns
```

---

## Types of Neural Networks (Detailed)

### 1. Feedforward Neural Network (FNN)

**Architecture:**
```
Input Layer â†’ Hidden Layer(s) â†’ Output Layer
     (forward only, no loops)

â”Œâ”€â”€â”€â”€â”€â”
â”‚  xâ‚ â”‚â”€â”€â”
â”œâ”€â”€â”€â”€â”€â”¤  â”‚  â”Œâ”€â”€â”€â”€â”
â”‚  xâ‚‚ â”‚â”€â”€â”¼â”€â†’â”‚ hâ‚ â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”˜  â”‚  â”œâ”€â”€â”€â”€â”¤  â”‚  â”Œâ”€â”€â”€â”€â”
         â””â”€â†’â”‚ hâ‚‚ â”‚â”€â”€â”¼â”€â†’â”‚ y  â”‚
            â””â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”˜
                    â”‚
                    â””â”€â†’
```

**How it Works:**
- Information moves in **one direction** only
- From input â†’ hidden â†’ output
- **No feedback loops**

**Use Cases:**
- âœ… Basic classification (spam detection)
- âœ… Simple pattern recognition
- âœ… Function approximation

**Key Point:**
- Simplest type of neural network
- Foundation for more complex architectures

---

### 2. Convolutional Neural Network (CNN)

**Architecture:**
```
Input Image â†’ Conv Layers â†’ Pooling â†’ Fully Connected â†’ Output

[Image] â†’ [Filters/Kernels] â†’ [Feature Maps] â†’ [Classification]
```

**How it Works:**
- Uses **filters (kernels)** to scan through data
- Detects patterns like:
  - **Edges** (low-level features)
  - **Shapes** (mid-level features)
  - **Objects** (high-level features)

**Key Operations:**
1. **Convolution:** Apply filters to detect patterns
2. **Pooling:** Reduce dimensionality
3. **Activation:** Add non-linearity (ReLU)

**Use Cases:**
- âœ… **Image recognition** (cats vs dogs)
- âœ… **Video analysis** (action recognition)
- âœ… **Medical imaging** (tumor detection)
- âœ… **Face recognition**

**Key Point:**
- **Best suited** for image and spatial data
- Automatically learns visual features

---

### 3. Recurrent Neural Network (RNN)

**Architecture:**
```
       â”Œâ”€â”€â”€â”€â”€â”€â”
    â”Œâ”€â†’â”‚Hiddenâ”‚â”€â”€â”
    â”‚  â”‚Layer â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
Input     â†“     Output
    â””â”€â”€â”€â”€Loopâ”€â”€â”€â”€â”˜
    (Recurrence)
```

**How it Works:**
- Has **connections that loop back**
- **Remembers** information from previous steps
- Maintains **internal state** (memory)

**Key Feature:**
```
Time step t-1 â†’ Time step t â†’ Time step t+1
     â†“              â†“              â†“
  Hidden State â†’ Hidden State â†’ Hidden State
  (remembers previous context)
```

**Use Cases:**
- âœ… **Language modeling** (predict next word)
- âœ… **Text prediction** (autocomplete)
- âœ… **Speech recognition** (transcription)
- âœ… **Time-series forecasting** (stock prices)

**Key Point:**
- Good for **sequential data** where order matters

**Limitation:**
- Struggles with **long sequences** (vanishing gradient)

---

### 4. Long Short-Term Memory (LSTM) Networks

**Architecture:**
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     LSTM Unit           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
Input â†’â”€â”¤  â”‚ Forget Gate        â”‚ â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
        â”‚  â”‚ Input Gate         â”‚ â”‚â†’ Output
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
        â”‚  â”‚ Input Modulation   â”‚ â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
        â”‚  â”‚ Output Gate        â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How it Works:**
- Special type of RNN
- Uses **memory cells** and **gates**:
  - **Forget Gate:** Decides what to forget
  - **Input Gate:** Decides what new info to store
  - **Output Gate:** Decides what to output

**Advantage over RNN:**
```
RNN:  Forgets long-term dependencies
LSTM: Remembers long-term dependencies
```

**Use Cases:**
- âœ… **Machine translation** (English â†’ French)
- âœ… **Chatbot responses** (context-aware)
- âœ… **Predicting stock prices** (long sequences)
- âœ… **Text generation** (writing stories)

**Key Point:**
- Designed to **remember long sequences**
- Solves vanishing gradient problem of RNNs

---

### 5. Generative Adversarial Networks (GANs)

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generator   â”‚â”€â”€â”€â”€â”€â”€â”€â†’â”‚Discriminator â”‚
â”‚  (Creates    â”‚  Fake  â”‚ (Real or     â”‚
â”‚   fake data) â”‚  Data  â”‚  Fake?)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚
       â””â”€â”€â”€â”€â”€ Compete â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         (improve each other)
```

**How it Works:**
- **Two networks compete:**
  1. **Generator:** Creates fake data
  2. **Discriminator:** Distinguishes real from fake

**Training Process:**
```
1. Generator creates fake images
2. Discriminator tries to identify fakes
3. Both improve through competition
4. Eventually, fakes become realistic
```

**Use Cases:**
- âœ… **Creating realistic images** (faces, art)
- âœ… **Deepfakes** (video generation)
- âœ… **Data augmentation** (generate training data)
- âœ… **Style transfer** (turn photos into paintings)

**Key Point:**
- Good at **generating new, realistic data**
- Revolutionary for creative AI

---

### 6. Self-Organizing Maps (SOMs)

**How it Works:**
- **Unsupervised network**
- Maps **high-dimensional data** â†’ **low dimension** (2D/3D)
- Preserves topological relationships

**Visualization:**
```
High-D Data      SOM Grid (2D)
â—  â—  â—          â”Œâ”€â”¬â”€â”¬â”€â”
â—  â—  â—    â†’     â”œâ”€â”¼â”€â”¼â”€â”¤
â—  â—  â—          â””â”€â”´â”€â”´â”€â”˜
(100D)           (Visualized)
```

**Use Cases:**
- âœ… **Data clustering** (group similar data)
- âœ… **Feature mapping** (visualize relationships)
- âœ… **Pattern recognition** (find similarities)

**Key Point:**
- Helps **visualize complex data**
- Useful for exploratory analysis

---

### 7. Modular Neural Networks (MNNs)

**How it Works:**
- Splits **big problem** into **smaller parts**
- Each part solved by **separate network**
- Results **combined** at the end

**Architecture:**
```
    Large Problem
         â†“
   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
   â†“           â†“
Module 1    Module 2   ... Module N
   â†“           â†“           â†“
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Combined Result
```

**Use Cases:**
- âœ… **Robotics** (vision + movement + planning)
- âœ… **Medical diagnosis** (multiple symptoms + tests)
- âœ… **Autonomous systems** (perception + decision + control)

**Key Point:**
- Breaks down **complex problems** into manageable modules
- Each module specializes in specific task

---

## Multi-Layer Neural Networks (MLP)

### What is an MLP?

**Definition:**  
An advanced neural network model with **multiple layers** of interconnected perceptrons.

**Key Difference from Perceptron:**
```
Perceptron:    Single layer
MLP:           Multiple layers stacked
```

**Structure:**
```
Input â†’ Hidden Layer(s) â†’ Output

Each layer:
- Receives input from previous layer
- Applies weights + bias
- Applies activation function
- Passes to next layer
```

---

## MLP Structure - Detailed

### 1. Input Layer

**Purpose:**  
Takes in raw features from dataset

**Example (Image Recognition):**
```
Each pixel value is an input

28Ã—28 image = 784 input neurons
```

**Characteristics:**
- âœ… No computation here
- âœ… Just passes data forward
- âœ… One neuron per feature

---

### 2. Hidden Layers

**Purpose:**  
Transform inputs into useful representations

**Process:**
```
For each hidden layer:
1. Weighted sum: z = Î£(wáµ¢xáµ¢) + b
2. Activation: a = Ï†(z)
3. Pass to next layer
```

**Learning Hierarchy (Example: Image Recognition):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INPUT LAYER                   â”‚
â”‚  Raw pixel values              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HIDDEN LAYER 1                â”‚
â”‚  Detects: Edges, lines, cornersâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HIDDEN LAYER 2                â”‚
â”‚  Detects: Shapes (circles, etc)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HIDDEN LAYER 3                â”‚
â”‚  Detects: Objects (faces, cars)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT LAYER                  â”‚
â”‚  Final classification          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Insight:**
- Deeper layers learn more abstract features
- Early layers: Low-level features (edges)
- Later layers: High-level features (objects)

---

### 3. Output Layer

**Purpose:**  
Produces final decision/prediction

**Examples:**

#### Binary Classification:
```
Single neuron:
  Output = probability of class 1
  
Example: Cat vs Dog
  [0.9] â†’ 90% chance of Cat
```

#### Multi-Class Classification:
```
Multiple neurons (one per class):
  Output = probability distribution
  
Example: Digit Recognition (0-9)
  [0.1, 0.05, 0.7, 0.05, 0.1, ...]
         â†‘
    Highest probability â†’ Predict "2"
```

---

### Complete MLP Example

**Problem:** Predict survival on Titanic

```
INPUT LAYER:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Age     â”‚ xâ‚€
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Gender  â”‚ xâ‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ PClass  â”‚ xâ‚‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
HIDDEN LAYER 1:
  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
  â”‚Î£wáµ¢xáµ¢ â”‚â†’â”‚ Ï†(Â·) â”‚  â”‚Î£wáµ¢xáµ¢ â”‚â†’â”‚ Ï†(Â·) â”‚  ...
  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
       â†“
HIDDEN LAYER 2:
  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
  â”‚Î£wáµ¢xáµ¢ â”‚â†’â”‚ Ï†(Â·) â”‚  â”‚Î£wáµ¢xáµ¢ â”‚â†’â”‚ Ï†(Â·) â”‚  ...
  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
       â†“
OUTPUT LAYER:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ P(Die)   â”‚  â”‚P(Survive)â”‚
  â”‚   0.3    â”‚  â”‚   0.9    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“              â†“
      [0]          [1]
     (Die)      (Survived)
```

**Prediction:** Survived (probability = 0.9)

---

## How Neural Networks Learn

### The Learning Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: FORWARD PROPAGATION           â”‚
â”‚  Data flows: Input â†’ Hidden â†’ Output  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: COMPUTE LOSS                  â”‚
â”‚  Measure error between prediction      â”‚
â”‚  and actual answer                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: BACKPROPAGATION               â”‚
â”‚  Send error backward to update weights â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: REPEAT                        â”‚
â”‚  Continue until network learns         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Forward Propagation

### Concept

**Idea:**  
Data flows **layer by layer** through the network. Each neuron performs:
1. Weighted sum
2. Add bias
3. Apply activation

**Mathematical Process:**

#### For Layer l:

**Step 1: Weights & Bias**
```
Wâ½Ë¡â¾ = weight matrix for layer l
bâ½Ë¡â¾ = bias vector for layer l
```

**Step 2: Pre-Activation (Weighted Sum)**
```
zâ½Ë¡â¾ = Wâ½Ë¡â¾ aâ½Ë¡â»Â¹â¾ + bâ½Ë¡â¾

where:
  aâ½Ë¡â»Â¹â¾ = activations from previous layer
```

**Step 3: Activation**
```
aâ½Ë¡â¾ = f(zâ½Ë¡â¾)

where:
  f(Â·) = activation function (ReLU, sigmoid, etc.)
```

---

### Output Layer

**Binary Classification:**
```
Å· = Ïƒ(z)  (sigmoid activation)

Output: Probability between 0 and 1
```

**Multi-Class Classification:**
```
Å· = softmax(z)

Output: Probability distribution
  Example: [0.1, 0.7, 0.2] sums to 1.0
```

---

### Example Forward Pass

```
Layer 0 (Input):     aâ½â°â¾ = [xâ‚, xâ‚‚, xâ‚ƒ]

Layer 1 (Hidden):
  zâ½Â¹â¾ = Wâ½Â¹â¾Â·aâ½â°â¾ + bâ½Â¹â¾
  aâ½Â¹â¾ = ReLU(zâ½Â¹â¾)

Layer 2 (Hidden):
  zâ½Â²â¾ = Wâ½Â²â¾Â·aâ½Â¹â¾ + bâ½Â²â¾
  aâ½Â²â¾ = ReLU(zâ½Â²â¾)

Layer 3 (Output):
  zâ½Â³â¾ = Wâ½Â³â¾Â·aâ½Â²â¾ + bâ½Â³â¾
  Å· = sigmoid(zâ½Â³â¾)

Final prediction: Å·
```

---

## Loss Function

### Purpose

**Measure "how wrong" the prediction is**

Compare prediction Å· with true label y.  
The loss is a **single number to minimize**.

---

### Common Loss Functions

#### 1. Binary Cross-Entropy (BCE)

**Use:** Binary classification (2 classes)

**Formula:**
```
L = -[y log(Å·) + (1-y)log(1-Å·)]

where:
  y  = true label (0 or 1)
  Å·  = predicted probability
```

**Example:**
```
True label:   y = 1 (Cat)
Predicted:    Å· = 0.9

Loss = -[1Ã—log(0.9) + 0Ã—log(0.1)]
     = -log(0.9)
     â‰ˆ 0.105  (small error, good!)

If Å· = 0.1:
Loss = -[1Ã—log(0.1) + 0Ã—log(0.9)]
     = -log(0.1)
     â‰ˆ 2.30  (large error, bad!)
```

---

#### 2. Categorical Cross-Entropy (CE)

**Use:** Multi-class classification (K classes)

**Formula:**
```
L = -Î£(k=1 to K) yâ‚– log(Å·â‚–)

where:
  yâ‚–  = true label (one-hot encoded)
  Å·â‚–  = predicted probability for class k
```

**Example:**
```
True label:   [0, 1, 0]  (class 2)
Predicted:    [0.1, 0.7, 0.2]

Loss = -[0Ã—log(0.1) + 1Ã—log(0.7) + 0Ã—log(0.2)]
     = -log(0.7)
     â‰ˆ 0.357
```

---

#### 3. Mean Squared Error (MSE)

**Use:** Regression tasks

**Formula:**
```
L = (1/n) Î£(Å· - y)Â²

where:
  n  = number of samples
  Å·  = predicted value
  y  = true value
```

**Example:**
```
True:     y = 5
Predicted: Å· = 4.5

Loss = (4.5 - 5)Â²
     = (-0.5)Â²
     = 0.25
```

---

## Loss Optimization

### The Goal

**Find weights W* that minimize the loss:**

```
W* = argmin_W [ (1/n) Î£ L(f(xâ½â±â¾; W), yâ½â±â¾) ]
              i=1 to n

where:
  W           = weights (parameters)
  f(xâ½â±â¾; W)  = model prediction for input xâ½â±â¾
  yâ½â±â¾        = true label for input xâ½â±â¾
  L(Â·,Â·)      = loss function
  n           = number of training examples
```

---

### Simplified Notation

```
W* = argmin_W J(W)

where:
  J(W) = cost function (average loss)
```

**Interpretation:**
```
Training a neural network means:
Adjusting weights W so predictions 
are as close as possible to true outputs,
by minimizing the loss (cost) function.
```

---

## Gradient Descent

### Concept

**Update parameters using the gradient of the loss function.**

**Visual Analogy:**
```
     Cost
      â”‚     â•±â•²
      â”‚   â•±    â•²
      â”‚ â•±        â•²    â† Start here
      â”‚â•±____      â•²
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Weights
         â†“
    Roll down hill
    to find minimum
```

---

### Gradient Descent Surfaces

**3D Cost Surface:**
```
J(wâ‚€, wâ‚)
   â•±â•²  â•±â•²
  â•±  â•²â•±  â•²   â† Multiple local minima
 â•±    â•±    â•²
â•±____â•±______â•²

Goal: Find lowest valley (global minimum)
```

**Gradient Descent Path:**
```
Starting Point â˜…
    â†“  â†“  â†“
    â†“  â†“  â†“  (Follow gradient)
    â†“  â†“  â†“
   Minimum âœ“
```

---

## Gradient Descent Algorithm

### Algorithm Steps

```python
# Pseudocode

# Step 1: Initialize weights randomly
W = random_normal(0, ÏƒÂ²)

# Step 2: Loop until convergence
while not converged:
    
    # Step 3: Compute gradient
    gradient = âˆ‚J(W)/âˆ‚W
    
    # Step 4: Update weights
    W = W - Î· Ã— gradient
    
# Step 5: Return final weights
return W
```

---

### Mathematical Formula

```
W â† W - Î· Ã— (âˆ‚J(W)/âˆ‚W)

where:
  W        = current weight
  Î·        = learning rate (step size)
  âˆ‚J(W)/âˆ‚W = gradient of loss w.r.t weight
  â†        = assignment (update)
```

---

### Update Equation Breakdown

**Current position:**
```
W_current
```

**Gradient (direction of steepest increase):**
```
âˆ‚J(W)/âˆ‚W
```

**Move in opposite direction:**
```
-Î· Ã— (âˆ‚J(W)/âˆ‚W)
```

**New position:**
```
W_new = W_current - Î· Ã— (âˆ‚J(W)/âˆ‚W)
```

---

### Learning Rate (Î·)

**Role:** Controls step size

```
Small Î· (e.g., 0.001):
  âœ… More stable
  âŒ Slow convergence
  
Large Î· (e.g., 0.1):
  âœ… Fast convergence
  âŒ May overshoot minimum
  âŒ May diverge

Optimal Î·:
  Balance speed and stability
```

---

## Backpropagation

### What is Backpropagation?

**Purpose:**  
Compute **gradients** efficiently to update all weights in the network.

**Process:**  
Propagate error **backwards** from output to input.

---

### Chain Rule

**Foundation of backpropagation:**

**Computational Graph:**
```
Input x â†’ Multiply by wâ‚ â†’ zâ‚ â†’ ... â†’ Å· â†’ Loss J(W)
```

**Chain Rule Formula:**
```
âˆ‚f(W)/âˆ‚wâ‚ = (âˆ‚f(W)/âˆ‚Å·) Ã— (âˆ‚Å·/âˆ‚zâ‚) Ã— (âˆ‚zâ‚/âˆ‚wâ‚)

Propagate gradient backward through each operation
```

---

### Backpropagation Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FORWARD PASS                          â”‚
â”‚  x â†’ zâ‚ â†’ aâ‚ â†’ zâ‚‚ â†’ aâ‚‚ â†’ ... â†’ Å· â†’ L â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COMPUTE LOSS                          â”‚
â”‚  L = loss(Å·, y)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BACKWARD PASS (Backpropagation)       â”‚
â”‚  âˆ‚L/âˆ‚Å· â† âˆ‚L/âˆ‚aâ‚‚ â† âˆ‚L/âˆ‚zâ‚‚ â† ... â† âˆ‚L/âˆ‚wâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UPDATE WEIGHTS                        â”‚
â”‚  W â† W - Î·Ã—(âˆ‚L/âˆ‚W)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Example: 3-Layer Network

**Forward Pass:**
```
Layer 0 (Input):
  aâ½â°â¾ = [xâ‚, xâ‚‚]

Layer 1 (Hidden):
  zâ½Â¹â¾ = Wâ½Â¹â¾aâ½â°â¾ + bâ½Â¹â¾
  aâ½Â¹â¾ = ReLU(zâ½Â¹â¾)

Layer 2 (Output):
  zâ½Â²â¾ = Wâ½Â²â¾aâ½Â¹â¾ + bâ½Â²â¾
  Å· = Ïƒ(zâ½Â²â¾)

Loss:
  L = BCE(Å·, y)
```

---

**Backward Pass:**
```
Output Layer:
  âˆ‚L/âˆ‚Å· = -(y/Å·) + (1-y)/(1-Å·)
  âˆ‚L/âˆ‚zâ½Â²â¾ = âˆ‚L/âˆ‚Å· Ã— Ïƒ'(zâ½Â²â¾)
  âˆ‚L/âˆ‚Wâ½Â²â¾ = âˆ‚L/âˆ‚zâ½Â²â¾ Ã— aâ½Â¹â¾áµ€
  âˆ‚L/âˆ‚bâ½Â²â¾ = âˆ‚L/âˆ‚zâ½Â²â¾

Hidden Layer:
  âˆ‚L/âˆ‚aâ½Â¹â¾ = Wâ½Â²â¾áµ€ Ã— âˆ‚L/âˆ‚zâ½Â²â¾
  âˆ‚L/âˆ‚zâ½Â¹â¾ = âˆ‚L/âˆ‚aâ½Â¹â¾ Ã— ReLU'(zâ½Â¹â¾)
  âˆ‚L/âˆ‚Wâ½Â¹â¾ = âˆ‚L/âˆ‚zâ½Â¹â¾ Ã— aâ½â°â¾áµ€
  âˆ‚L/âˆ‚bâ½Â¹â¾ = âˆ‚L/âˆ‚zâ½Â¹â¾
```

---

**Update Weights:**
```
Wâ½Â²â¾ â† Wâ½Â²â¾ - Î· Ã— âˆ‚L/âˆ‚Wâ½Â²â¾
bâ½Â²â¾ â† bâ½Â²â¾ - Î· Ã— âˆ‚L/âˆ‚bâ½Â²â¾
Wâ½Â¹â¾ â† Wâ½Â¹â¾ - Î· Ã— âˆ‚L/âˆ‚Wâ½Â¹â¾
bâ½Â¹â¾ â† bâ½Â¹â¾ - Î· Ã— âˆ‚L/âˆ‚bâ½Â¹â¾
```

---

### Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Layer                         â”‚
â”‚  â— â—  (xâ‚, xâ‚‚, bias)                â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Wâ½Â¹â¾, bâ½Â¹â¾
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hidden Layer                        â”‚
â”‚  â— â— â—  (hâ‚, hâ‚‚, hâ‚ƒ)                â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚ Wâ½Â²â¾, bâ½Â²â¾
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Layer                        â”‚
â”‚  â—  (yâ‚, yâ‚‚)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Forward: Data flows â†“ (compute predictions)
Backward: Gradients flow â†‘ (compute âˆ‚L/âˆ‚W)
```

---

## Summary

### Key Concepts Covered

```
NEURAL NETWORKS:
â”œâ”€â”€ Inspired by biological neurons
â”œâ”€â”€ Layers of interconnected nodes
â”œâ”€â”€ Weights + Bias + Activation
â””â”€â”€ Learn through training

PERCEPTRON:
â”œâ”€â”€ Simplest neural network
â”œâ”€â”€ Binary classifier
â”œâ”€â”€ Linear separability limitation
â””â”€â”€ Foundation for deep learning

ACTIVATION FUNCTIONS:
â”œâ”€â”€ Sigmoid (0, 1)
â”œâ”€â”€ Tanh (-1, 1)
â”œâ”€â”€ ReLU [0, âˆ) - Most popular
â””â”€â”€ Leaky ReLU (-âˆ, âˆ)

LEARNING PROCESS:
â”œâ”€â”€ Forward Propagation (make prediction)
â”œâ”€â”€ Loss Function (measure error)
â”œâ”€â”€ Backpropagation (compute gradients)
â””â”€â”€ Gradient Descent (update weights)

TYPES OF NETWORKS:
â”œâ”€â”€ Feedforward (FNN)
â”œâ”€â”€ Convolutional (CNN) - Images
â”œâ”€â”€ Recurrent (RNN/LSTM) - Sequences
â””â”€â”€ GANs - Generation
```

---

## Thank You!

### Course Information
- **Module:** IT2011 - Artificial Intelligence and Machine Learning
- **Lecture:** 7 - Neural Networks and Deep Learning
- **Lecturer:** Dr. Lakmini Abeywardhana
- **Institution:** SLIIT - Sri Lanka Institute of Information Technology
- **Faculty:** Faculty of Computing
- **Academic Year:** Year 02, Semester 01
- **Student:** IT24103352
- **Date:** 2025-01-23

---

### Next Steps

**What's Coming:**
- Lecture 8: Advanced Neural Network Architectures (CNN, RNN, LSTM)
- Practical implementation of neural networks
- Deep learning frameworks (TensorFlow, PyTorch)

**Recommended Practice:**
1. âœ… Implement perceptron from scratch
2. âœ… Build simple multi-layer network
3. âœ… Experiment with different activation functions
4. âœ… Understand backpropagation mathematically
5. âœ… Try different loss functions
6. âœ… Visualize learning process

---

**End of Lecture 7**

**Total Pages:** 37  
**Completion Status:** âœ… Fully converted to Markdown
